{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8GSJSVcUdrO"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38527,
     "status": "ok",
     "timestamp": 1549860677984,
     "user": {
      "displayName": "Boinapalli Pavan Kumar",
      "photoUrl": "",
      "userId": "04058542146316836750"
     },
     "user_tz": 360
    },
    "id": "gzliujOKUdrQ",
    "outputId": "d6cb0abf-3faa-459a-9f8c-b87e1bb0bbc3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import requests\n",
    "import random\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn.feature_selection import mutual_info_regression,SelectKBest,f_regression,VarianceThreshold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import OrderedDict\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C9QiU9XOUdrW"
   },
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYpIRNUpUdrX"
   },
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "#Reading all test csvs and merging them\n",
    "testfiles = glob.glob(curr_dir+\"/Testing/TestSet/*.csv\")\n",
    "test_df = pd.DataFrame()\n",
    "for testfile in testfiles:\n",
    "    if test_df.shape[0] == 0:\n",
    "        test_df = pd.read_csv(testfile,header=None)\n",
    "    else:\n",
    "        test_df = pd.concat([test_df,pd.read_csv(testfile,header=None)])\n",
    "        \n",
    "# reading train csv        \n",
    "train_df = pd.read_csv(curr_dir+\"/Training/Features_Variant_1.csv\",header=None)\n",
    "\n",
    "#Constructing feature Labels\n",
    "features = [\"PageLikes\",\"PageCheckins\",\"PageTalkingAbout\",\"PageCategory\"]\n",
    "features.extend([\"derived_\"+str(i) for i in range(1,26)])\n",
    "features.extend([\"CC1\",\"CC2\",\"CC3\",\"CC4\",\"CC5\",\"BaseTime\",\"PostLength\",\"PostShareCount\",\"PostPromotionStatus\",\"Hhours\"])\n",
    "features.extend([\"PostPublishedWeekday\"+str(i) for i in range(1,8)])\n",
    "features.extend([\"BaseTimeWeekDay\"+str(i) for i in range(1,8)])\n",
    "features.extend([\"Target\"])\n",
    "\n",
    "#renaming train and test column names\n",
    "train_df.columns = features\n",
    "test_df.columns = features\n",
    "data_df = pd.concat([train_df,test_df],ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "igaHqLCPUdrb"
   },
   "source": [
    "# Selecting 11 features from dataset using statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45673,
     "status": "ok",
     "timestamp": 1549860685158,
     "user": {
      "displayName": "Boinapalli Pavan Kumar",
      "photoUrl": "",
      "userId": "04058542146316836750"
     },
     "user_tz": 360
    },
    "id": "_2TZCjJHUdrc",
    "outputId": "98b87464-dfd1-4b67-a57c-0ce0e87dd598"
   },
   "outputs": [],
   "source": [
    "\n",
    "data_x = data_df.iloc[:,:-1]\n",
    "data_y = data_df.iloc[:,-1:]\n",
    "\n",
    "\n",
    "data_x_scaled = pd.DataFrame(MinMaxScaler().fit_transform(data_x),columns=data_x.columns.values)\n",
    "data_x_bestfit = SelectKBest(f_regression,k=41).fit(data_x_scaled, data_y)\n",
    "data_x_filtered = data_x_scaled.iloc[:,data_x_bestfit.get_support()]\n",
    "data_x_filtered = data_x_filtered.loc[:,((data_x_filtered.corr()>0.5).sum()>1)==False].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvo0ET3EUdrf"
   },
   "source": [
    "# Splitting data into train test in ration of 70 : 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rr_ihseAUdrg"
   },
   "outputs": [],
   "source": [
    "def split_and_return_coefficients(data_x,data_y,frac,target_label,intercept_label):\n",
    "  train_data = data_x.sample(frac=0.7,random_state=111)\n",
    "  train_target = data_y.loc[train_data.index.tolist()][target_label]\n",
    "\n",
    "  test_data = data_x.drop(train_data.index.values)\n",
    "  test_target = data_y.loc[test_data.index.tolist()][target_label]\n",
    "\n",
    "  #Building coefficients and initializing with random values\n",
    "  coefficients = ['b0']\n",
    "  coefficients.extend(['b'+str(i) for i in train_data.columns.values])\n",
    "\n",
    "\n",
    "  train_data.insert(0,intercept_label,[1]*len(train_data.index))\n",
    "  test_data.insert(0,intercept_label,[1]*len(test_data.index))\n",
    "  \n",
    "  return coefficients,train_data,test_data,train_target,test_target\n",
    "\n",
    "coefficients,train_data,test_data,train_target,test_target = split_and_return_coefficients(data_x_filtered,data_y,0.7,\"Target\",\"Intercept\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCAqXuMSUdro"
   },
   "source": [
    "# Parameter estimation using batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45882,
     "status": "ok",
     "timestamp": 1549860685383,
     "user": {
      "displayName": "Boinapalli Pavan Kumar",
      "photoUrl": "",
      "userId": "04058542146316836750"
     },
     "user_tz": 360
    },
    "id": "-HbHHctkUdro",
    "outputId": "9c9a22a8-283e-481a-b49c-b1090490e939"
   },
   "outputs": [],
   "source": [
    "#n_samples is number of samples in training set\n",
    "n_samples = len(train_data.index)\n",
    "\n",
    "#Initialize random coefficient values\n",
    "coeff_values_dict = OrderedDict((coeff,np.random.uniform(0,0.01)) for coeff in coefficients)\n",
    "coeff_values = list(coeff_values_dict.values())\n",
    "print(\"Initial coeff parameter values are:\")\n",
    "coeff_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HX1_4o1qUdrs"
   },
   "outputs": [],
   "source": [
    "def getHypothesisValue(coeff_values_h,training_hypoth):\n",
    "    if not isinstance(training_hypoth,pd.DataFrame):\n",
    "        print(\"df expected found something else\")\n",
    "    else:\n",
    "        hypothesis_value = np.dot(training_hypoth,coeff_values_h)\n",
    "        return hypothesis_value\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ea87xu_3Udrv"
   },
   "outputs": [],
   "source": [
    "def getMSEValue(example_matrix,example_target,coeff_values_mse):\n",
    "    error = np.subtract(getHypothesisValue(coeff_values_mse,example_matrix),example_target)\n",
    "    squared_error = np.dot(np.transpose(error),error)\n",
    "    mean_squared_error = squared_error/(2*len(example_target))\n",
    "    return mean_squared_error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScxgjaJqUdry"
   },
   "outputs": [],
   "source": [
    "def gradientUpdate(train_g,train_target_g,coeff_values_g,alpha_g):\n",
    "    error = np.subtract(getHypothesisValue(coeff_values_g,train_g),train_target_g)\n",
    "    updated_coeff_values = coeff_values_g - (alpha_g/len(train_target_g))*(np.dot(train_g.T.as_matrix(),error))\n",
    "    return updated_coeff_values\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UeRb6gKWUdr2"
   },
   "outputs": [],
   "source": [
    "def converge(converge_train,converge_train_target,converge_test,converge_test_target,converge_coeff_values,converge_alpha,converge_threshold,converge_max_iter):\n",
    "    n_samples_c = len(converge_train)\n",
    "    converge_trigger = 0\n",
    "    increasing_trigger = 0\n",
    "    train_loss = [getMSEValue(converge_train,converge_train_target,converge_coeff_values)]\n",
    "    test_loss = [getMSEValue(converge_test,converge_test_target,converge_coeff_values)]\n",
    "    while(True):\n",
    "      converge_coeff_values = gradientUpdate(converge_train,converge_train_target,converge_coeff_values,converge_alpha)\n",
    "      error_change = (train_loss[-1]-getMSEValue(converge_train,converge_train_target,converge_coeff_values))/train_loss[-1]\n",
    "      if(converge_trigger == 10 or increasing_trigger==100):\n",
    "        break\n",
    "      if ((error_change>0 and error_change<=converge_threshold) or len(train_loss)>=converge_max_iter):\n",
    "        converge_trigger +=1\n",
    "      elif error_change<0:\n",
    "        increasing_trigger +=1\n",
    "      else:\n",
    "        converge_trigger = 0\n",
    "        increasing_trigger = 0\n",
    "        tl = getMSEValue(converge_train,converge_train_target,converge_coeff_values)\n",
    "        ttl = getMSEValue(converge_test,converge_test_target,converge_coeff_values)\n",
    "        train_loss.append(tl)\n",
    "        test_loss.append(ttl)\n",
    "          \n",
    "    output_dict = {}\n",
    "    output_dict[\"iterations\"] = len(train_loss)-1\n",
    "    output_dict[\"train_loss\"] = train_loss\n",
    "    output_dict[\"test_loss\"] = test_loss  \n",
    "    output_dict[\"coeff_values\"] = converge_coeff_values\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00azmLN_Udr8"
   },
   "source": [
    "# Part1 : Varying alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1441564,
     "status": "ok",
     "timestamp": 1549862081097,
     "user": {
      "displayName": "Boinapalli Pavan Kumar",
      "photoUrl": "",
      "userId": "04058542146316836750"
     },
     "user_tz": 360
    },
    "id": "S-NdKLZ-Udr9",
    "outputId": "a31cd2cc-c3bf-4099-ae8e-96aa0523f6a6"
   },
   "outputs": [],
   "source": [
    "alpha_values = [0.0001,0.001,0.01,0.05,0.1,0.5,0.8,1,2]\n",
    "def get_best_alpha(alpha_values,train_data_a,train_target_a,test_data_a,test_target_a,coeff_values_a,threshold_a,max_iter_a):\n",
    "  results = []\n",
    "  for alpha_a in alpha_values:\n",
    "    results.append(converge(train_data_a,train_target_a,test_data_a,test_target_a,coeff_values_a,alpha_a,threshold_a,max_iter_a))\n",
    "  return results\n",
    "\n",
    "def alpha_plot(results):\n",
    "    for i,j in enumerate(results):\n",
    "      plt.subplot(121)\n",
    "      plt.plot(j[\"train_loss\"],label=alpha_values[i])\n",
    "      plt.legend()\n",
    "      plt.xlabel(\"iterations\")\n",
    "      plt.ylabel(\"Training Error\")\n",
    "      plt.title(\"Train Error convergence for various alpha\")\n",
    "      plt.subplot(122)\n",
    "      plt.plot(j[\"test_loss\"],label=alpha_values[i])\n",
    "      plt.xlabel(\"iterations\")\n",
    "      plt.ylabel(\"Test Error\")\n",
    "      plt.title(\"Test Error convergence for various alphas\")\n",
    "      plt.legend()\n",
    "      plt.subplots_adjust(left=0.5, right=3)\n",
    "alpha_results = get_best_alpha(alpha_values,train_data,train_target,test_data,test_target,coeff_values,0.000001,30000)\n",
    "alpha_plot(alpha_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1441559,
     "status": "ok",
     "timestamp": 1549862081098,
     "user": {
      "displayName": "Boinapalli Pavan Kumar",
      "photoUrl": "",
      "userId": "04058542146316836750"
     },
     "user_tz": 360
    },
    "id": "dvK_4MteWl7k",
    "outputId": "6d35553a-bd1c-46f2-c159-63c4be2f4f45"
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "for i,j in enumerate(alpha_results):\n",
    "  train_losses.append(j[\"train_loss\"][-1])\n",
    "  test_losses.append(j[\"test_loss\"][-1])\n",
    "\n",
    "plt.subplot(111)\n",
    "plt.plot(train_losses,label=\"Train Errors\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Train and Test Error for various alpha\")\n",
    "plt.plot(test_losses,label=\"Test Errors\")\n",
    "plt.legend()\n",
    "plt.xticks(range(len(alpha_values)+1),alpha_values)\n",
    "plt.subplots_adjust(left=0.5, right=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wT_Lca6t7UiG"
   },
   "source": [
    "We choose 0.5 as best alpha because it converges faster than the alpha values below it and alpha values above 0.5 the function do not converge to minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5qDYwib-Udr_"
   },
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1760923,
     "status": "ok",
     "timestamp": 1549862400471,
     "user": {
      "displayName": "Boinapalli Pavan Kumar",
      "photoUrl": "",
      "userId": "04058542146316836750"
     },
     "user_tz": 360
    },
    "id": "U65KQ1D3UdsA",
    "outputId": "0d5fd887-2f54-4485-e1f7-8c306c2e9c9d"
   },
   "outputs": [],
   "source": [
    "threshold_list = [0.001,0.0001,0.00001,0.000001,0.0000001]\n",
    "alpha = 0.5\n",
    "output = []\n",
    "for thres in threshold_list:\n",
    "  result = converge(train_data,train_target,test_data,test_target,coeff_values,0.5,thres,15000)\n",
    "  output.append(result)\n",
    "  \n",
    "plt.subplot(121)\n",
    "plt.plot([result[\"train_loss\"][-1] for result in output])\n",
    "plt.xlabel(\"Threshold Value as percent change\")\n",
    "plt.ylabel(\"Train Error\")\n",
    "plt.xticks(range(len(threshold_list)+1),threshold_list)\n",
    "plt.title(\"Train Error variation on Threshold Value\")\n",
    "plt.subplot(122)\n",
    "plt.plot([result[\"test_loss\"][-1] for result in output])\n",
    "plt.xlabel(\"Threshold Value as percent change\")\n",
    "plt.ylabel(\"Test Error\")\n",
    "plt.xticks(range(len(threshold_list)+1),threshold_list)\n",
    "plt.title(\"Test Error variation on Threshold Value\")\n",
    "plt.subplots_adjust(left=0.5, right=3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1760920,
     "status": "ok",
     "timestamp": 1549862400473,
     "user": {
      "displayName": "Boinapalli Pavan Kumar",
      "photoUrl": "",
      "userId": "04058542146316836750"
     },
     "user_tz": 360
    },
    "id": "biL4xjF8Cuhd",
    "outputId": "15eabe9e-e006-4541-d443-6cded3472f5b"
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.plot(output[3][\"train_loss\"],label=\"Train Error\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.plot(output[3][\"test_loss\"],label=\"Test Error\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.title(\"Train and Test loss vs iterations for best threshold\")\n",
    "plt.subplots_adjust(left=0.5, right=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "93ZzRL9iUdsB"
   },
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBTNEul9GCf-"
   },
   "source": [
    "We will randomly choose 5 features and compare error value of this model  with error values of original 11 feature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Q23Xf2zUdsC"
   },
   "outputs": [],
   "source": [
    "\n",
    "#choosing five features randomly\n",
    "final_ex= data_x_scaled[list(np.random.choice(features[:-1],5,replace=False))]\n",
    "coefficients_ex,train_ex,test_ex,train_target_ex,test_target_ex = split_and_return_coefficients(final_ex,data_y,0.7,\"Target\",\"Intercept\")\n",
    "\n",
    "\n",
    "#Initialize random coefficient values\n",
    "coeff_values_dict_ex = OrderedDict((coeff,np.random.uniform(0,0.1)) for coeff in coefficients_ex)\n",
    "coeff_values_ex = list(coeff_values_dict_ex.values())\n",
    "\n",
    "alpha_results = get_best_alpha(alpha_values,train_ex,train_target_ex,test_ex,test_target_ex,coeff_values_ex,0.000001,15000)\n",
    "alpha_plot(alpha_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vp9_eyHSJcLE"
   },
   "outputs": [],
   "source": [
    "#choose best alpha\n",
    "alpha_ex = 0.5\n",
    "\n",
    "\n",
    "#choosing threshold Error value\n",
    "threshold_ex = 0.000001\n",
    "\n",
    "\n",
    "result_ex = converge(train_ex,train_target_ex,test_ex,test_target_ex,coeff_values_ex,alpha_ex,threshold_ex,15000)\n",
    "\n",
    "print(\"random features are:\",final_ex.columns.values)\n",
    "print(\"Training error for five random features model is: \",result_ex[\"train_loss\"][-1])\n",
    "print(\"Test error for five random features model is: \", result_ex[\"test_loss\"][-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MuU_e4zsN4wT"
   },
   "outputs": [],
   "source": [
    "\n",
    "#original data\n",
    "coefficients,train,test,train_target,test_target = split_and_return_coefficients(data_x_filtered,data_y,0.7,\"Target\",\"Intercept\")\n",
    "\n",
    "\n",
    "\n",
    "#Initialize random coefficient values\n",
    "coeff_values_dict = OrderedDict((coeff,np.random.uniform(0,0.1)) for coeff in coefficients)\n",
    "coeff_values = list(coeff_values_dict.values())\n",
    "\n",
    "\n",
    "#choosing alpha\n",
    "alpha = 0.5\n",
    "\n",
    "#choosing threshold Error value\n",
    "threshold = 0.000001\n",
    "\n",
    "\n",
    "result = converge(train,train_target,test,test_target,coeff_values,alpha,threshold,15000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training error for five random features model is: \",result[\"train_loss\"][-1])\n",
    "print(\"Test error for five random features model is: \", result[\"test_loss\"][-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c2jXMx3qN1Mw"
   },
   "outputs": [],
   "source": [
    "experiment_df = pd.DataFrame(index=[\"five_featues_random\",\"11 featues\"])\n",
    "experiment_df[\"train_loss\"] = [result_ex[\"train_loss\"][-1],result[\"train_loss\"][-1]]\n",
    "experiment_df[\"test_loss\"] = [result_ex[\"test_loss\"][-1],result[\"test_loss\"][-1]]\n",
    "experiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fL09j1yGUdsN"
   },
   "source": [
    "# Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cQ5yvqQmF025"
   },
   "source": [
    "I think these features \"PageLikes\",\"PageCheckins\",\"PageTalkingAbout\",\"PostShareCount\",\"Hhours\" are important according to my intuition and we will findout how these features perform against random 5 features model and original 11 featuers model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55n2Z6_8UdsP"
   },
   "outputs": [],
   "source": [
    "# chosing 5 best features\n",
    "final_filtered_ex4= data_x_scaled[[\"PageLikes\",\"PageCheckins\",\"PageTalkingAbout\",\"PostShareCount\",\"Hhours\"]]\n",
    "final_transformed_ex4 = pd.DataFrame(MinMaxScaler().fit_transform(final_filtered_ex4),columns=final_filtered_ex4.columns)\n",
    "coefficients_ex4,train_ex4,test_ex4,train_target_ex4,test_target_ex4 = split_and_return_coefficients(final_transformed_ex4,data_y,0.7,\"Target\",\"Intercept\")\n",
    "\n",
    "\n",
    "\n",
    "#Initialize random coefficient values\n",
    "coeff_values_dict_ex4 = OrderedDict((coeff,np.random.uniform(0,0.1)) for coeff in coefficients_ex4)\n",
    "coeff_values_ex4 = list(coeff_values_dict_ex4.values())\n",
    "\n",
    "\n",
    "alpha_results = get_best_alpha(alpha_values,train_ex4,train_target_ex4,test_ex4,test_target_ex4,coeff_values_ex4,0.000001,15000)\n",
    "alpha_plot(alpha_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YID2_fcsJXqd"
   },
   "outputs": [],
   "source": [
    "#choosing alpha\n",
    "alpha_ex4 = 0.5\n",
    "\n",
    "#choosing threshold Error value\n",
    "threshold_ex4 = 0.000001\n",
    "\n",
    "result_ex4 = converge(train_ex4,train_target_ex4,test_ex4,test_target_ex4,coeff_values_ex4,alpha_ex4,threshold_ex4,15000)\n",
    "\n",
    "print(\"Training error for five random features model is: \",result_ex4[\"train_loss\"][-1])\n",
    "print(\"Test error for five random features model is: \", result_ex4[\"test_loss\"][-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UoJggEZUdsZ"
   },
   "outputs": [],
   "source": [
    "experiment_df.loc[\"5 best\"] = [result_ex4[\"train_loss\"][-1],result_ex4[\"test_loss\"][-1]]\n",
    "experiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zw2OElHPb3wG"
   },
   "outputs": [],
   "source": [
    "five_best = train_ex4\n",
    "five_best[\"target\"] = train_target_ex4.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyNPO6vRnOhP"
   },
   "outputs": [],
   "source": [
    "five_random = train_ex\n",
    "five_random['target'] = train_target_ex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7XB5oeeFnipN"
   },
   "outputs": [],
   "source": [
    "print(\"five random feature model\")\n",
    "five_random.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9Vg7WBwnlnS"
   },
   "outputs": [],
   "source": [
    "print(\"five best features model\")\n",
    "five_best.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2iEb5JEAvsp3"
   },
   "source": [
    "# Final Equation with Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-WfqdoibvvH0"
   },
   "outputs": [],
   "source": [
    "for beta,feature in zip(result[\"coeff_values\"],train.columns.values):\n",
    "  print(\"{} * \".format(beta)+feature+\" + \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZwCmX2yMyHit"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of HomeWork1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
